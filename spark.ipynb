{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/06 17:18:57 WARN Utils: Your hostname, luks-note resolves to a loopback address: 127.0.1.1; using 192.168.0.7 instead (on interface wlp0s20f3)\n",
      "24/01/06 17:18:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/06 17:18:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql as ssql\n",
    "\n",
    "spark = ssql.SparkSession.builder.master('local') \\\n",
    "    .appName('myAppName') \\\n",
    "    .config('spark.executor.memory', '5gb') \\\n",
    "    .config(\"spark.cores.max\", \"6\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"./results_compressed/gerador_residuo_solido.parquet\")\n",
    "# df.printSchema()\n",
    "# df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/serializers.py\", line 459, in dumps\n",
      "    return cloudpickle.dumps(obj, pickle_protocol)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/cloudpickle/cloudpickle_fast.py\", line 632, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "TypeError: cannot pickle '_thread.RLock' object\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: TypeError: cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/serializers.py:459\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/cloudpickle/cloudpickle_fast.py:73\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     70\u001b[0m cp \u001b[38;5;241m=\u001b[39m CloudPickler(\n\u001b[1;32m     71\u001b[0m     file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/cloudpickle/cloudpickle_fast.py:632\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rdd \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallelize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py:824\u001b[0m, in \u001b[0;36mSparkContext.parallelize\u001b[0;34m(self, c, numSlices)\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonParallelizeServer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc(), numSlices)\n\u001b[0;32m--> 824\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize_to_jvm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreateRDDServer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RDD(jrdd, \u001b[38;5;28mself\u001b[39m, serializer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py:867\u001b[0m, in \u001b[0;36mSparkContext._serialize_to_jvm\u001b[0;34m(self, data, serializer, reader_func, server_func)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 867\u001b[0m         \u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m         tempFile\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/serializers.py:225\u001b[0m, in \u001b[0;36mBatchedSerializer.dump_stream\u001b[0;34m(self, iterator, stream)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, stream):\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/serializers.py:147\u001b[0m, in \u001b[0;36mFramedSerializer.dump_stream\u001b[0;34m(self, iterator, stream)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, stream):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_with_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/serializers.py:157\u001b[0m, in \u001b[0;36mFramedSerializer._write_with_length\u001b[0;34m(self, obj, stream)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_with_length\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, stream):\n\u001b[0;32m--> 157\u001b[0m     serialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m serialized \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialized value should not be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/serializers.py:469\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    467\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not serialize object: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, emsg)\n\u001b[1;32m    468\u001b[0m print_exec(sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m--> 469\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPicklingError(msg)\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not serialize object: TypeError: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./word_count.sql\", \"r\") as f:\n",
    "    query = f.read()\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH \n",
    "\n",
    "splited AS (\n",
    "    SELECT \n",
    "\n",
    "    cast(regexp_replace(regexp_replace(quantidadegerada, '[.]', ''), ',', '.') as double) as quantidadegerada,\n",
    "    anogeracao,\n",
    "    CASE \n",
    "        WHEN unidade=\"Litro\"      AND classificacaoresiduo=\"Perigoso\"       THEN 'Líquido Perigoso'\n",
    "        WHEN unidade=\"Litro\"      AND classificacaoresiduo=\"Não Perigoso\"   THEN 'Líquido Não Perigoso'\n",
    "        WHEN unidade=\"kilogramas\" AND classificacaoresiduo=\"Perigoso\"       THEN 'Sólido Perigoso'\n",
    "        WHEN unidade=\"kilogramas\" AND classificacaoresiduo=\"Não Perigoso\"   THEN 'Sólido Não Perigoso'\n",
    "        WHEN unidade=\"Unidade\" AND classificacaoresiduo=\"Perigoso\"       THEN 'Outro Perigoso'\n",
    "        WHEN unidade=\"Unidade\" AND classificacaoresiduo=\"Não Perigoso\"   THEN 'Outro Não Perigoso'\n",
    "        ELSE 'Outro'\n",
    "    END AS tipo,\n",
    "    split(lower(regexp_replace(detalhe, '[^a-zA-Z0-9áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙäëïöüÄËÏÖÜâêîôûÂÊÎÔÛãñõÃÑÕçÇ°º]', ' ')), ' ') as detalhe,\n",
    "    split(lower(regexp_replace(tiporesiduo, '[^a-zA-Z0-9áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙäëïöüÄËÏÖÜâêîôûÂÊÎÔÛãñõÃÑÕçÇ°º]', ' ')), ' ') as tiporesiduo,\n",
    "    split(lower(regexp_replace(categoriaatividade, '[^a-zA-Z0-9áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙäëïöüÄËÏÖÜâêîôûÂÊÎÔÛãñõÃÑÕçÇ°º]', ' ')), ' ') as categoriaatividade,\n",
    "    split(lower(regexp_replace(razaosocialgerador, '[^a-zA-Z0-9áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙäëïöüÄËÏÖÜâêîôûÂÊÎÔÛãñõÃÑÕçÇ°º]', ' ')), ' ') as razaosocialgerador\n",
    "\n",
    "    FROM Gerador\n",
    "),\n",
    "\n",
    "exp_detalhe AS (\n",
    "    SELECT \n",
    "        word,\n",
    "        anogeracao,\n",
    "        tipo,\n",
    "        SUM(COALESCE(CAST(detalhe AS FLOAT), 0)) AS detalhe\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            explode(detalhe) AS word,\n",
    "            anogeracao,\n",
    "            tipo,\n",
    "            CASE \n",
    "                WHEN quantidadegerada IS NULL OR quantidadegerada = '' THEN '0'\n",
    "                ELSE quantidadegerada\n",
    "            END AS detalhe\n",
    "        FROM splited\n",
    "    ) AS exploded_words\n",
    "    WHERE NOT (word RLIKE '^[0-9]+([,.][0-9]+)?$') AND word != ''\n",
    "    GROUP BY word, anogeracao, tipo\n",
    "    ORDER BY word DESC\n",
    "),\n",
    "\n",
    "exp_tiporesiduo AS (\n",
    "    SELECT \n",
    "        word,\n",
    "        anogeracao,\n",
    "        tipo,\n",
    "        SUM(COALESCE(CAST(tiporesiduo AS FLOAT), 0)) AS tiporesiduo\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            explode(tiporesiduo) AS word,\n",
    "            anogeracao,\n",
    "            tipo,\n",
    "            CASE \n",
    "                WHEN quantidadegerada IS NULL OR quantidadegerada = '' THEN '0'\n",
    "                ELSE quantidadegerada\n",
    "            END AS tiporesiduo\n",
    "        FROM splited\n",
    "    ) AS exploded_words\n",
    "    WHERE NOT (word RLIKE '^[0-9]+([,.][0-9]+)?$') AND word != ''\n",
    "    GROUP BY word, anogeracao, tipo\n",
    "    ORDER BY word DESC\n",
    "),\n",
    "\n",
    "exp_categoriaatividade AS (\n",
    "    SELECT \n",
    "        word,\n",
    "        anogeracao,\n",
    "        tipo,\n",
    "        SUM(COALESCE(CAST(categoriaatividade AS FLOAT), 0)) AS categoriaatividade\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            explode(categoriaatividade) AS word,\n",
    "            anogeracao,\n",
    "            tipo,\n",
    "            CASE \n",
    "                WHEN quantidadegerada IS NULL OR quantidadegerada = '' THEN '0'\n",
    "                ELSE quantidadegerada\n",
    "            END AS categoriaatividade\n",
    "        FROM splited\n",
    "    ) AS exploded_words\n",
    "    WHERE NOT (word RLIKE '^[0-9]+([,.][0-9]+)?$') AND word != ''\n",
    "    GROUP BY word, anogeracao, tipo\n",
    "    ORDER BY word DESC\n",
    "),\n",
    "\n",
    "exp_razaosocialgerador AS (\n",
    "    SELECT \n",
    "        word,\n",
    "        anogeracao,\n",
    "        tipo,\n",
    "        SUM(COALESCE(CAST(razaosocialgerador AS FLOAT), 0)) AS razaosocialgerador\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            explode(razaosocialgerador) AS word,\n",
    "            anogeracao,\n",
    "            tipo,\n",
    "            CASE \n",
    "                WHEN quantidadegerada IS NULL OR quantidadegerada = '' THEN '0'\n",
    "                ELSE quantidadegerada\n",
    "            END AS razaosocialgerador\n",
    "        FROM splited\n",
    "    ) AS exploded_words\n",
    "    WHERE NOT (word RLIKE '^[0-9]+([,.][0-9]+)?$') AND word != ''\n",
    "    GROUP BY word, anogeracao, tipo\n",
    "    ORDER BY word DESC\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    COALESCE(\n",
    "        exp_detalhe.word, \n",
    "        exp_tiporesiduo.word, \n",
    "        exp_categoriaatividade.word, \n",
    "        exp_razaosocialgerador.word\n",
    "        ) AS word,\n",
    "    COALESCE(\n",
    "        exp_detalhe.anogeracao, \n",
    "        exp_tiporesiduo.anogeracao, \n",
    "        exp_categoriaatividade.anogeracao, \n",
    "        exp_razaosocialgerador.anogeracao\n",
    "        ) AS anogeracao,\n",
    "    COALESCE(\n",
    "        exp_detalhe.tipo, \n",
    "        exp_tiporesiduo.tipo, \n",
    "        exp_categoriaatividade.tipo, \n",
    "        exp_razaosocialgerador.tipo\n",
    "        ) AS tipo,  \n",
    "    COALESCE(detalhe, 0) AS detalhe,\n",
    "    COALESCE(tiporesiduo, 0) AS tiporesiduo,\n",
    "    COALESCE(categoriaatividade, 0) AS categoriaatividade,\n",
    "    COALESCE(razaosocialgerador, 0) AS razaosocialgerador\n",
    "\n",
    "FROM exp_detalhe \n",
    "FULL OUTER JOIN exp_tiporesiduo \n",
    "ON exp_detalhe.word = exp_tiporesiduo.word \n",
    "AND exp_detalhe.anogeracao = exp_tiporesiduo.anogeracao\n",
    "AND exp_detalhe.tipo = exp_tiporesiduo.tipo\n",
    "\n",
    "FULL OUTER JOIN exp_categoriaatividade \n",
    "ON COALESCE(exp_detalhe.word, exp_tiporesiduo.word) = exp_categoriaatividade.word\n",
    "AND COALESCE(exp_detalhe.anogeracao, exp_tiporesiduo.anogeracao) = exp_categoriaatividade.anogeracao\n",
    "AND COALESCE(exp_detalhe.tipo, exp_tiporesiduo.tipo) = exp_categoriaatividade.tipo\n",
    "\n",
    "FULL OUTER JOIN exp_razaosocialgerador \n",
    "ON COALESCE(exp_detalhe.word, exp_tiporesiduo.word, exp_categoriaatividade.word) = exp_razaosocialgerador.word\n",
    "AND COALESCE(exp_detalhe.anogeracao, exp_tiporesiduo.anogeracao, exp_categoriaatividade.anogeracao) = exp_razaosocialgerador.anogeracao\n",
    "AND COALESCE(exp_detalhe.tipo, exp_tiporesiduo.tipo, exp_categoriaatividade.tipo) = exp_razaosocialgerador.tipo\n",
    "\n",
    ";\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SqlQuery0 = \"\"\"\n",
    "WITH \n",
    "\n",
    "splited AS (\n",
    "    SELECT \n",
    "    cast(regexp_replace(regexp_replace(quantidadegerada, '[.]', ''), ',', '.') as double) as quantidadegerada,\n",
    "    anogeracao,\n",
    "    CASE \n",
    "        WHEN unidade=\"Litro\"      AND classificacaoresiduo=\"Perigoso\"       THEN 'Líquido Perigoso'\n",
    "        WHEN unidade=\"Litro\"      AND classificacaoresiduo=\"Não Perigoso\"   THEN 'Líquido Não Perigoso'\n",
    "        WHEN unidade=\"kilogramas\" AND classificacaoresiduo=\"Perigoso\"       THEN 'Sólido Perigoso'\n",
    "        WHEN unidade=\"kilogramas\" AND classificacaoresiduo=\"Não Perigoso\"   THEN 'Sólido Não Perigoso'\n",
    "        WHEN unidade=\"Unidade\" AND classificacaoresiduo=\"Perigoso\"       THEN 'Outro Perigoso'\n",
    "        WHEN unidade=\"Unidade\" AND classificacaoresiduo=\"Não Perigoso\"   THEN 'Outro Não Perigoso'\n",
    "        ELSE 'Outro'\n",
    "    END AS tipo,\n",
    "    split(lower(regexp_replace(detalhe, '[^a-zA-Z0-9áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙäëïöüÄËÏÖÜâêîôûÂÊÎÔÛãñõÃÑÕçÇ°º]', ' ')), ' ') as detalhe,\n",
    "    split(lower(regexp_replace(tiporesiduo, '[^a-zA-Z0-9áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙäëïöüÄËÏÖÜâêîôûÂÊÎÔÛãñõÃÑÕçÇ°º]', ' ')), ' ') as tiporesiduo,\n",
    "    split(lower(regexp_replace(categoriaatividade, '[^a-zA-Z0-9áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙäëïöüÄËÏÖÜâêîôûÂÊÎÔÛãñõÃÑÕçÇ°º]', ' ')), ' ') as categoriaatividade,\n",
    "    split(lower(regexp_replace(razaosocialgerador, '[^a-zA-Z0-9áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙäëïöüÄËÏÖÜâêîôûÂÊÎÔÛãñõÃÑÕçÇ°º]', ' ')), ' ') as razaosocialgerador\n",
    "\n",
    "    FROM myDataSource\n",
    "),\n",
    "\n",
    "exp_detalhe AS (\n",
    "    SELECT \n",
    "        word,\n",
    "        anogeracao,\n",
    "        tipo,\n",
    "        SUM(COALESCE(CAST(detalhe AS FLOAT), 0)) AS detalhe\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            explode(detalhe) AS word,\n",
    "            anogeracao,\n",
    "            tipo,\n",
    "            CASE \n",
    "                WHEN quantidadegerada IS NULL OR quantidadegerada = '' THEN '0'\n",
    "                ELSE quantidadegerada\n",
    "            END AS detalhe\n",
    "        FROM splited\n",
    "    ) AS exploded_words\n",
    "    WHERE NOT (word RLIKE '^[0-9]+([,.][0-9]+)?$') AND word != ''\n",
    "    GROUP BY word, anogeracao, tipo\n",
    "    ORDER BY word DESC\n",
    "),\n",
    "\n",
    "exp_tiporesiduo AS (\n",
    "    SELECT \n",
    "        word,\n",
    "        anogeracao,\n",
    "        tipo,\n",
    "        SUM(COALESCE(CAST(tiporesiduo AS FLOAT), 0)) AS tiporesiduo\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            explode(tiporesiduo) AS word,\n",
    "            anogeracao,\n",
    "            tipo,\n",
    "            CASE \n",
    "                WHEN quantidadegerada IS NULL OR quantidadegerada = '' THEN '0'\n",
    "                ELSE quantidadegerada\n",
    "            END AS tiporesiduo\n",
    "        FROM splited\n",
    "    ) AS exploded_words\n",
    "    WHERE NOT (word RLIKE '^[0-9]+([,.][0-9]+)?$') AND word != ''\n",
    "    GROUP BY word, anogeracao, tipo\n",
    "    ORDER BY word DESC\n",
    "),\n",
    "\n",
    "exp_categoriaatividade AS (\n",
    "    SELECT \n",
    "        word,\n",
    "        anogeracao,\n",
    "        tipo,\n",
    "        SUM(COALESCE(CAST(categoriaatividade AS FLOAT), 0)) AS categoriaatividade\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            explode(categoriaatividade) AS word,\n",
    "            anogeracao,\n",
    "            tipo,\n",
    "            CASE \n",
    "                WHEN quantidadegerada IS NULL OR quantidadegerada = '' THEN '0'\n",
    "                ELSE quantidadegerada\n",
    "            END AS categoriaatividade\n",
    "        FROM splited\n",
    "    ) AS exploded_words\n",
    "    WHERE NOT (word RLIKE '^[0-9]+([,.][0-9]+)?$') AND word != ''\n",
    "    GROUP BY word, anogeracao, tipo\n",
    "    ORDER BY word DESC\n",
    "),\n",
    "\n",
    "exp_razaosocialgerador AS (\n",
    "    SELECT \n",
    "        word,\n",
    "        anogeracao,\n",
    "        tipo,\n",
    "        SUM(COALESCE(CAST(razaosocialgerador AS FLOAT), 0)) AS razaosocialgerador\n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "            explode(razaosocialgerador) AS word,\n",
    "            anogeracao,\n",
    "            tipo,\n",
    "            CASE \n",
    "                WHEN quantidadegerada IS NULL OR quantidadegerada = '' THEN '0'\n",
    "                ELSE quantidadegerada\n",
    "            END AS razaosocialgerador\n",
    "        FROM splited\n",
    "    ) AS exploded_words\n",
    "    WHERE NOT (word RLIKE '^[0-9]+([,.][0-9]+)?$') AND word != ''\n",
    "    GROUP BY word, anogeracao, tipo\n",
    "    ORDER BY word DESC\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    COALESCE(\n",
    "        exp_detalhe.word, \n",
    "        exp_tiporesiduo.word, \n",
    "        exp_categoriaatividade.word, \n",
    "        exp_razaosocialgerador.word\n",
    "        ) AS word,\n",
    "    COALESCE(\n",
    "        exp_detalhe.anogeracao, \n",
    "        exp_tiporesiduo.anogeracao, \n",
    "        exp_categoriaatividade.anogeracao, \n",
    "        exp_razaosocialgerador.anogeracao\n",
    "        ) AS anogeracao,\n",
    "    COALESCE(\n",
    "        exp_detalhe.tipo, \n",
    "        exp_tiporesiduo.tipo, \n",
    "        exp_categoriaatividade.tipo, \n",
    "        exp_razaosocialgerador.tipo\n",
    "        ) AS tipo,  \n",
    "    COALESCE(detalhe, 0) AS detalhe,\n",
    "    COALESCE(tiporesiduo, 0) AS tiporesiduo,\n",
    "    COALESCE(categoriaatividade, 0) AS categoriaatividade,\n",
    "    COALESCE(razaosocialgerador, 0) AS razaosocialgerador\n",
    "\n",
    "FROM exp_detalhe \n",
    "FULL OUTER JOIN exp_tiporesiduo \n",
    "ON exp_detalhe.word = exp_tiporesiduo.word \n",
    "AND exp_detalhe.anogeracao = exp_tiporesiduo.anogeracao\n",
    "AND exp_detalhe.tipo = exp_tiporesiduo.tipo\n",
    "\n",
    "FULL OUTER JOIN exp_categoriaatividade \n",
    "ON COALESCE(exp_detalhe.word, exp_tiporesiduo.word) = exp_categoriaatividade.word\n",
    "AND COALESCE(exp_detalhe.anogeracao, exp_tiporesiduo.anogeracao) = exp_categoriaatividade.anogeracao\n",
    "AND COALESCE(exp_detalhe.tipo, exp_tiporesiduo.tipo) = exp_categoriaatividade.tipo\n",
    "\n",
    "FULL OUTER JOIN exp_razaosocialgerador \n",
    "ON COALESCE(exp_detalhe.word, exp_tiporesiduo.word, exp_categoriaatividade.word) = exp_razaosocialgerador.word\n",
    "AND COALESCE(exp_detalhe.anogeracao, exp_tiporesiduo.anogeracao, exp_categoriaatividade.anogeracao) = exp_razaosocialgerador.anogeracao\n",
    "AND COALESCE(exp_detalhe.tipo, exp_tiporesiduo.tipo, exp_categoriaatividade.tipo) = exp_razaosocialgerador.tipo\n",
    "\n",
    ";\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.from_options(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gerador = sc.create_dynamic_frame.from_options(\n",
    "    format_options={},\n",
    "    connection_type=\"s3\",\n",
    "    format=\"parquet\",\n",
    "    connection_options={\n",
    "        \"paths\": [\n",
    "            \"s3://jm2vtech/pos/residuos_solidos_ibama/results_compressed/gerador_residuo_solido.parquet\"\n",
    "        ],\n",
    "        \"recurse\": True,\n",
    "    },\n",
    "    transformation_ctx=\"Gerador\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SqlQuery0.replace(\"myDataSource\", \"Gerador\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DynamicFrame.fromDF(SqlQuery0.replace(\"myDataSource\", \"Gerador\"), sc, transformation_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparkSqlQuery(glueContext, query, mapping, transformation_ctx) -> DynamicFrame:\n",
    "    for alias, frame in mapping.items():\n",
    "        frame.toDF().createOrReplaceTempView(alias)\n",
    "    result = spark.sql(query)\n",
    "    return DynamicFrame.fromDF(result, glueContext, transformation_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split_map_reduce = sparkSqlQuery(\n",
    "    glueContext,\n",
    "    query=SqlQuery0,\n",
    "    mapping={\"myDataSource\": Gerador},\n",
    "    transformation_ctx=\"text_split_map_reduce\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# basic configuration from external file\n",
    "with open(\"./config.json\") as file:\n",
    "    config = dict(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(read_raw_json(\"results_raw/gerador_residuo_solido.json\"))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_terminal = config[\"terminal_log\"]\n",
    "# log_terminal = True # config[\"terminal_log\"]\n",
    "\n",
    "max_proc = multiprocessing.cpu_count()\n",
    "max_proc = config[\"max_proc\"] if config[\"max_proc\"] < max_proc else max_proc\n",
    "\n",
    "# total values in a df\n",
    "chunk_size = int(1e6)\n",
    "chunk_size = df.size if chunk_size > df.size else chunk_size\n",
    "\n",
    "\n",
    "#amount of rows in each chunk\n",
    "chunk_rows = int(chunk_size/df.shape[1])\n",
    "\n",
    "\n",
    "chunks = [df.iloc[i:i + chunk_rows] for i in range(0, df.shape[0], chunk_rows)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_df_num(df):\n",
    "    return df.map(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "\n",
    "results = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "with multiprocessing.Pool(\n",
    "    processes = (max_proc if len(chunks) > max_proc else len(chunks))\n",
    "    ) as pool:\n",
    "    with tqdm(total=len(chunks), position=0, leave=True, disable=(not log_terminal)) as global_pbar:\n",
    "        for result in pool.imap_unordered(\n",
    "            fix_df_num,\n",
    "            chunks,\n",
    "            chunksize=1\n",
    "            ):\n",
    "            results = pd.concat([results, result])\n",
    "            global_pbar.update()\n",
    "\n",
    "results.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(results).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Function to be executed by each worker in the pool\n",
    "def process_column(column_name):\n",
    "    return df[column_name].apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "\n",
    "df = pd.DataFrame.from_dict(read_raw_json(\"results_raw/gerador_residuo_solido.json\"))\n",
    "\n",
    "# Setting up multiprocessing pool\n",
    "with multiprocessing.Pool(processes=multiprocessing.cpu_count() -1) as pool:\n",
    "    results = list(tqdm(pool.imap(process_column, df.columns), total=len(df.columns)))\n",
    "\n",
    "# Combine results back into a single DataFrame\n",
    "df_converted = pd.concat(results, axis=1)\n",
    "\n",
    "df_converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_converted.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(\n",
    "    read_raw_json(\n",
    "        \"results_raw/gerador_residuo_solido.json\"\n",
    "        ),\n",
    ")\n",
    "df = df.map(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    j[\"name\"]:pd.read_parquet(f'{config[\"local\"][\"path_result_compressed\"]}{j[\"name\"]}_{j[\"category\"]}.parquet')\n",
    "    for j in config[\"raw_source\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"armazenador\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2][\"data\"][\"anoDestinacao\"].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[2][\"data\"][\"anoDestinacao\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word,\n",
    "coalesce(c.d_razaosocialdestinador, 0),\n",
    "coalesce(c.d_descresiduo, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "\n",
    "\n",
    "FROM (\n",
    "    (\n",
    "        SELECT d_razaosocialdestinador.d_razaosocialdestinador  AS word, \n",
    "        COUNT(*) AS d_razaosocialdestinador\n",
    "        FROM d_razaosocialdestinador \n",
    "        GROUP BY d_razaosocialdestinador\n",
    "    ) a\n",
    "    \n",
    "    FULL OUTER JOIN \n",
    "\n",
    "    (\n",
    "        SELECT d_descresiduo.d_descresiduo  AS word, \n",
    "        COUNT(*) AS d_descresiduo\n",
    "        FROM d_descresiduo \n",
    "        GROUP BY d_descresiduo\n",
    "    ) b\n",
    "\n",
    "    ON a.word = b.word\n",
    ") c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    \n",
    "    COALESCE(\n",
    "        LOWER(\n",
    "            REPLACE(\n",
    "                REPLACE(\n",
    "                    REPLACE(\n",
    "                        REPLACE(\n",
    "                            REPLACE(\n",
    "                                REPLACE(\n",
    "                                    REPLACE(\n",
    "                                        REPLACE(\n",
    "                                            REPLACE(\n",
    "                                            razaoSocialtransportador, \n",
    "                                            '!', ''), \n",
    "                                        '?', ''), \n",
    "                                    '.', ''), \n",
    "                                ',', ''), \n",
    "                            ';', ''), \n",
    "                        ':', ''),\n",
    "                    '\"', ''),\n",
    "                '`', ''),\n",
    "            '  ', ' ')\n",
    "        ),\n",
    "    razaoSocialtransportador) AS d_razaoSocialtransportador,\n",
    "    \n",
    "    \n",
    "    COALESCE(\n",
    "        LOWER(\n",
    "            REPLACE(\n",
    "                REPLACE(\n",
    "                    REPLACE(\n",
    "                        REPLACE(\n",
    "                            REPLACE(\n",
    "                                REPLACE(\n",
    "                                    REPLACE(\n",
    "                                        REPLACE(\n",
    "                                            REPLACE(\n",
    "                                            razaosocialorigem, \n",
    "                                            '!', ''), \n",
    "                                        '?', ''), \n",
    "                                    '.', ''), \n",
    "                                ',', ''), \n",
    "                            ';', ''), \n",
    "                        ':', ''),\n",
    "                    '\"', ''),\n",
    "                '`', ''),\n",
    "            '  ', ' ')\n",
    "        ),\n",
    "    razaosocialorigem) AS d_razaosocialorigem\n",
    "FROM myDataSource;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    COALESCE(\n",
    "        LOWER(\n",
    "            REPLACE(\n",
    "                REPLACE(\n",
    "                    REPLACE(\n",
    "                        REPLACE(\n",
    "                            REPLACE(\n",
    "                                REPLACE(\n",
    "                                    REPLACE(\n",
    "                                        REPLACE(\n",
    "                                            REPLACE(\n",
    "                                                razaosocialgerador, \n",
    "                                            '!', ''), \n",
    "                                        '?', ''), \n",
    "                                    '.', ''), \n",
    "                                ',', ''), \n",
    "                            ';', ''), \n",
    "                        ':', ''),\n",
    "                    '\"', ''),\n",
    "                '`', ''),\n",
    "            '  ', ' ')\n",
    "        ),\n",
    "    razaosocialgerador) AS d_razaosocialgerador"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
